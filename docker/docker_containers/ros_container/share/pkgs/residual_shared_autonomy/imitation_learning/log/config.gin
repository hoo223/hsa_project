import residual_shared_autonomy.imitation_learning

# Parameters for Adam:
# ==============================================================================
Adam.amsgrad = False
Adam.betas = (0.9, 0.999)
Adam.eps = 1e-08
Adam.lr = 0.001
Adam.weight_decay = 0

# Parameters for BCNet:
# ==============================================================================
BCNet.action_shape = 6
BCNet.nunits = 128
BCNet.ob_shape = 6

# Parameters for BCTrainer:
# ==============================================================================
BCTrainer.batch_size = 32
BCTrainer.datafile = './data/test2'
BCTrainer.gpu = True
BCTrainer.model = @BCNet()
BCTrainer.num_workers = 1
BCTrainer.opt = @optim.Adam

# Parameters for Checkpointer:
# ==============================================================================
Checkpointer.ckpt_period = 2
Checkpointer.format = '{:09d}'

# Parameters for DemonstrationData:
# ==============================================================================
DemonstrationData.mean = None
DemonstrationData.std = None

# Parameters for DiagGaussian:
# ==============================================================================
DiagGaussian.constant_log_std = False
DiagGaussian.log_std_max = 2
DiagGaussian.log_std_min = -20

# Parameters for train:
# ==============================================================================
train.algorithm = @BCTrainer
train.eval = True
train.eval_period = 1
train.maxseconds = None
train.maxt = 100
train.save_period = 1
train.seed = 0
